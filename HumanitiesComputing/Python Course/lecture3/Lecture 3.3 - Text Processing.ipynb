{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 3.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Text Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading files is just the first step. In most cases, we'd like to process larger (collections of) texts, and extract information by, for example, counting specific items such as words (but it can be anything, really, depending on your research question.)\n",
    "\n",
    "In the remainder of this lecture, we'll make our hands dirty on some real-world examples, we'll look at some operations common in text processing, and interrogate actual books. \n",
    "\n",
    "In what follows, you get a closer a look at all the steps that come with such as simple taks as counting words.\n",
    "\n",
    "Word-counting is very rudimentary, but nonetheless useful form of content analysis. Moretti coined the term 'distant reading' to argue that texts can be interpreted at some level of abstraction. \n",
    "\n",
    "In the next lecture we proceeding with more refined instruments, but the techniques snows here should provide you with  rudimentary tools for text-analysis at scale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Loading a collection of files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we take off, let's load our first data set that contains some of the works of the philosopher John Locke."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is somewhat different as what we have done until now. Instead of loading just *one* file, we now load a collection of texts. You could to this file by file (which works for a handful of file, but not for, let's say, thousands--unless you are very patient) but Python provides you with a more convenient to do this. What we need here is function from the `os` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above line, loads the Python `os` module. [CS] A module is a file that contains a collection of related functions grouped together. `os`, in this case stands for Operating Systems, as module provides you with an interface to interact with underlying Mac, Windows of Linux system on your computer.\n",
    "\n",
    "With the `help()` function we can get a sense what this module contains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "help(os)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This function takes as argument the path to a directory and returns all the files and subdirectories present in that directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['John Locke - Second Treatise of Government.txt',\n",
       " 'John Locke - An Essay Concerning Humane Understanding Volume I.txt',\n",
       " 'John Locke - An Essay Concerning Humane Understanding Volume II.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('data/locke')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[CS] To call one of the functions of the module, we have to specify the name of the module and the name of the function, separated by a dot, also known as a period. This format is called **dot notation**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[PH] Remember how to read files? Each time we had to open a file, read the contents and then close the file. Since this is a series of steps we will often need to do, we can write a single function that does all that for us. We write a small utility function read_file(filename) that reads the specified file and simply returns all contents as a single string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    \"Read the contents of FILENAME and return as a string.\"\n",
    "    with open(filename) as infile: # windows users should use codecs.open after importing codecs\n",
    "        contents = infile.read()\n",
    "    return contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, instead of having to open a file, read the contents and close the file, we can just call the function read_file to do all that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE EPISTLE TO THE READER\n",
      "\n",
      "READER,\n",
      "\n",
      "I have put into thy hands what has been the diversion of some of my idle and heavy hours. \n",
      "If it has the good luck to prove so of any of thine, and thou hast but half so much pleasure in reading as I had in writing it, thou wilt as little think thy money, as I do my pains, ill bestowed.\n",
      "Mistake not this for a commendation of my work; nor conclude, because I was pleased with the doing of it, that therefore I am fondly taken with\n",
      "it now it is done. \n",
      "He that hawks at larks and sparrows has no less sport, though a much less considerable quarry, than he that flies at nobler game: and he is little acquainted with the subject of this treatise--the UNDERSTANDING--who does not know that, as it is the most elevated faculty of the soul, so it is employed with a greater and more constant delight than any of the other. \n",
      "Its searches after truth are a sort of hawking and hunting, wherein the very pursuit makes a great part of the pleasure. \n",
      "Every step the mind takes in its progress towards Knowledge makes some discovery, which is not only new, but the best too, for the time at least.\n",
      "\n",
      "For the understanding, like the eye, judging of objects only by its own sight, cannot but be pleased with what it discovers, having less regret\n",
      "for what has escaped it, because it is unknown. \n",
      "Thus he who has raised himself above the alms-basket, and, not content to live lazily on scraps of begged opinions, sets his own thoughts on work, to find and follow truth, will (whatever he lights on) not miss the hunterâ€™s satisfaction; every moment of his pursuit will reward his pains with some delight; and he will have reason to think his time not ill spent, even when he cannot much boast of any great acquisition.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = read_file(\"data/locke_excerpt.txt\")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def list_textfiles(directory):\n",
    "    \"Return a list of filenames ending in '.txt' in DIRECTORY.\"\n",
    "    textfiles = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            textfiles.append(os.path.join(directory,filename))\n",
    "    return textfiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function listdir takes as argument the name of a directory and lists all filenames in that directory. We iterate over this list and append each filename that ends with the extension, .txt to a new list of textfiles. Using the list_textfiles function, the following code will read all text files in the directory data/gutenberg/training and outputs the length (in characters) of each:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/locke/John Locke - Second Treatise of Government.txt has 313912 characters.\n",
      "data/locke/John Locke - An Essay Concerning Humane Understanding Volume I.txt has 834572 characters.\n",
      "data/locke/John Locke - An Essay Concerning Humane Understanding Volume II.txt has 705611 characters.\n"
     ]
    }
   ],
   "source": [
    "for filepath in list_textfiles(\"data/locke\"):\n",
    "    text = read_file(filepath)\n",
    "    print(filepath +  \" has \" + str(len(text)) + \" characters.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now store all of Locke's works in a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts = []\n",
    "for filepath in list_textfiles(\"data/locke\"):\n",
    "    texts.append(read_file(filepath)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "The built-in in `join()` function concatenates these seperate works into one string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before join()\n",
      "3\n",
      "<class 'list'>\n",
      "\n",
      "\n",
      "After join()\n",
      "1854097\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print('Before join()')\n",
    "print(len(texts))\n",
    "print(type(texts))\n",
    "texts_joined = '\\n'.join(texts)\n",
    "print('\\n')\n",
    "print('After join()')\n",
    "print(len(texts_joined))\n",
    "print(type(texts_joined))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[CS] The join function is the inverse of split. It takes a list of strings and concatenates the elements with a space between each pair:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After split(' ')\n",
      "['Singing', 'in', 'the', 'rain']\n",
      "\n",
      "\n",
      "After ' '.join()\n",
      "Singing in the rain\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Singing in the rain\"\n",
    "print(\"After split(' ')\")\n",
    "words = sentence.split(\" \")\n",
    "print(words)\n",
    "joined_words = ' '.join(words)\n",
    "print(\"\\n\")\n",
    "print(\"After ' '.join()\")\n",
    "print(joined_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "The string before the dot defines the delimiter to insert between the different elements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Singing BLABLABLA in BLABLABLA the BLABLABLA rain\n"
     ]
    }
   ],
   "source": [
    "print(' BLABLABLA '.join(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1. Writing a count functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "[PH]Just to recap some of the stuff we learnt in the previous chapter. Can you write code that defines the variable `number_of_es` and counts how many times the letter *e* occurs in `texts_joined`? (Tip: use a `for` loop and an `if` statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "number_of_es = 0\n",
    "# insert your code here\n",
    "for character in texts_joined:\n",
    "    if character == 'e':\n",
    "        number_of_es += 1\n",
    "\n",
    "# The following test should print True if your code is correct \n",
    "print(number_of_es == 183448)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[PH]In the previous quiz, you probably wrote a loop that iterates over all characters in `text` and adds 1 to `number_of_es` each time the program finds the letter *e*. Counting objects in a text is a very common thing to do. Therefore, Python provides the convenient function `count`. This function operates on strings (`somestring.count(argument)`) and takes as argument the object you want to count. Using this function, the solution to the quiz above can now be rewritten as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183448\n"
     ]
    }
   ],
   "source": [
    "number_of_es = texts_joined.count(\"e\")\n",
    "print(number_of_es)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, `count` takes as argument any string you would like to find. We could just as well count how often the determiner `an` occurs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24416\n"
     ]
    }
   ],
   "source": [
    "print(texts_joined.count(\"an\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The string `an` is found 24416 times in our text. Does that mean that the word *an* occurs 24416 times in our No, in fact, *an* (the word) occurs only approximately  760... Think about this. Why then does Python print 24416?\n",
    "\n",
    "If we want to count how often the word *an* occurs in the text and not the string `an`, we could surround *an* with spaces, like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760\n"
     ]
    }
   ],
   "source": [
    "print(texts_joined.count(\" an \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although it gets the job done in this particular case, it is generally not a very solid way of counting words in a text. What if there are instances of *an* followd by a semicolon or some end-of-sentence marker? Then we would need to query the text multiple times for each possible context of *an*. For that reason, we're going to approach the problem using a different, more sophisticated strategy. \n",
    "\n",
    "Recall from the previous chapter the function `split`. What does this function do? The function `split` operates on a string and splits a string on spaces and returns a list of smaller strings (or words):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SECOND', 'TREATISE', 'OF', 'GOVERNMENT', 'by', 'JOHN', 'LOCKE', 'Digitized', 'by', 'Dave', 'Gowan', '<dgowan@tfn.net>.', 'John', \"Locke's\", '\"Second', 'Treatise', 'of', 'Government\"', 'was', 'published', 'in', '1690.', 'The', 'complete', 'unabridged', 'text', 'has', 'been', 'republished', 'several', 'times', 'in', 'edited', 'commentaries.', 'This', 'text', 'is', 'recovered', 'entire', 'from', 'the', 'paperback', 'book,', '\"John', 'Locke', 'Second', 'Treatise', 'of', 'Government\",', 'Edited,', 'with', 'an', 'Introduction,', 'By', 'C.B.', 'McPherson,', 'Hackett', 'Publishing', 'Company,', 'Indianapolis', 'and', 'Cambridge,', '1980.', 'None', 'of', 'the', 'McPherson', 'edition', 'is', 'included', 'in', 'the', 'Etext', 'below;', 'only', 'the', 'original', 'words', 'contained', 'in', 'the', '1690', 'Locke', 'text', 'is', 'included.', 'The', '1690', 'edition', 'text', 'is', 'free', 'of', 'copyright.', '*', '*', '*', '*', '*', 'TWO']\n"
     ]
    }
   ],
   "source": [
    "text = texts_joined.split()\n",
    "print(text[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Counting with dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous chapter you have acquainted yourself with the `dictionary` structure. Recall that a dictionary consists of keys and values and allows you to quickly lookup a value. We will use a dictionary to write the function `counter` that takes as argument a list and returns a `dictionary` with for each unique item the number of times it occurs in the list. We wil first write some code without the function declaration. If that works, we will add it, just as before, to the body of a function.\n",
    "\n",
    "We start with defining a variable `counts` which is an empty dictionary:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will loop over all words in our list `words`. For each word, we check whether the dictionary already contains it. If so, we add 1 to its value. If not, we first add the word to the dictionary and assign to it the value 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only use the first 1000 words as an example, but should work on the whole collections of texts as well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = text[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counts = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SECOND': 1, 'TREATISE': 1, 'OF': 5, 'GOVERNMENT': 2, 'by': 5, 'JOHN': 1, 'LOCKE': 2, 'Digitized': 1, 'Dave': 1, 'Gowan': 1, '<dgowan@tfn.net>.': 1, 'John': 1, \"Locke's\": 1, '\"Second': 1, 'Treatise': 2, 'of': 31, 'Government\"': 1, 'was': 3, 'published': 2, 'in': 14, '1690.': 1, 'The': 4, 'complete': 1, 'unabridged': 1, 'text': 4, 'has': 5, 'been': 3, 'republished': 1, 'several': 2, 'times': 2, 'edited': 1, 'commentaries.': 1, 'This': 1, 'is': 8, 'recovered': 1, 'entire': 1, 'from': 3, 'the': 40, 'paperback': 1, 'book,': 1, '\"John': 1, 'Locke': 2, 'Second': 1, 'Government\",': 1, 'Edited,': 1, 'with': 8, 'an': 6, 'Introduction,': 1, 'By': 1, 'C.B.': 1, 'McPherson,': 1, 'Hackett': 1, 'Publishing': 1, 'Company,': 1, 'Indianapolis': 1, 'and': 28, 'Cambridge,': 1, '1980.': 1, 'None': 1, 'McPherson': 1, 'edition': 2, 'included': 1, 'Etext': 1, 'below;': 1, 'only': 3, 'original': 1, 'words': 2, 'contained': 1, '1690': 2, 'included.': 1, 'free': 1, 'copyright.': 1, '*': 5, 'TWO': 2, 'TREATISES': 2, 'BY': 2, 'IOHN': 1, 'SALUS': 1, 'POPULI': 1, 'SUPREMA': 1, 'LEX': 1, 'ESTO': 1, 'LONDON': 1, 'PRINTED': 1, 'MDCLXXXVIII': 1, 'REPRINTED,': 1, 'THE': 5, 'SIXTH': 1, 'TIME,': 1, 'A.': 2, 'MILLAR,': 1, 'H.': 1, 'WOODFALL,': 1, '1.': 4, 'WHISTON': 1, 'AND': 8, 'B.': 2, 'WHITE,': 1, 'RIVINGTON,': 2, 'L.': 1, 'DAVIS': 1, 'C.': 3, 'REYMERS,': 1, 'R.': 3, 'BALDWIN,': 1, 'HAWES': 1, 'CLARKE': 1, 'COLLINS;': 1, 'W.': 2, 'IOHNSTON,': 1, 'OWEN,': 1, 'RICHARDSON,': 1, 'S.': 2, 'CROWDER,': 1, 'T.': 2, 'LONGMAN,': 1, 'LAW,': 1, 'E.': 1, 'DILLY,': 1, 'WITHY,': 1, 'WARE,': 1, 'BAKER,': 1, 'PAYNE,': 1, 'SHUCKBURGH,': 1, 'HINXMAN': 1, 'MDCCLXIII': 1, 'GOVERNMENT.': 2, 'IN': 1, 'FORMER': 1, 'FALSE': 1, 'PRINCIPLES': 1, 'FOUNDATION': 1, 'SIR': 1, 'ROBERT': 1, 'FILMER': 1, 'HIS': 1, 'FOLLOWERS': 1, 'ARE': 1, 'DETECTED': 1, 'OVERTHROWN.': 1, 'LATTER': 1, 'IS': 1, 'AN': 1, 'ESSAY': 1, 'CONCERNING': 1, 'TRUE': 1, 'ORIGINAL': 1, 'EXTENT': 1, 'END': 1, 'CIVIL': 1, '1764': 1, \"EDITOR'S\": 1, 'NOTE': 1, 'present': 2, 'Edition': 1, 'this': 4, 'Book': 1, 'not': 10, 'collated': 1, 'first': 1, 'three': 1, 'Editions,': 1, 'which': 7, 'were': 3, 'during': 1, \"Author's\": 1, 'Life,': 1, 'but': 1, 'also': 1, 'Advantage': 1, 'his': 12, 'last': 2, 'Corrections': 1, 'Improvements,': 1, 'a': 6, 'Copy': 1, 'delivered': 1, 'him': 5, 'to': 30, 'Mr.': 1, 'Peter': 1, 'Coste,': 1, 'communicated': 1, 'Editor,': 1, 'now': 1, 'lodged': 1, 'Christ': 1, 'College,': 1, 'Cambridge.': 1, 'PREFACE': 1, 'Reader,': 1, 'thou': 1, 'hast': 1, 'here': 3, 'beginning': 1, 'end': 1, 'discourse': 1, 'concerning': 2, 'government;': 2, 'what': 3, 'fate': 1, 'otherwise': 1, 'disposed': 1, 'papers': 2, 'that': 7, 'should': 5, 'have': 13, 'filled': 1, 'up': 5, 'middle,': 1, 'more': 2, 'than': 4, 'all': 6, 'rest,': 1, 'it': 4, 'worth': 3, 'while': 2, 'tell': 1, 'thee.': 1, 'These,': 1, 'remain,': 1, 'I': 13, 'hope': 2, 'are': 4, 'sufficient': 1, 'establish': 1, 'throne': 1, 'our': 3, 'great': 2, 'restorer,': 1, 'King': 1, 'William;': 1, 'make': 3, 'good': 1, 'title,': 1, 'consent': 1, 'people,': 2, 'being': 1, 'one': 3, 'lawful': 1, 'governments,': 1, 'he': 7, 'fully': 1, 'clearly,': 1, 'any': 5, 'prince': 2, 'Christendom;': 1, 'justify': 2, 'world': 1, 'people': 1, 'England,': 1, 'whose': 1, 'love': 1, 'their': 3, 'just': 2, 'natural': 1, 'rights,': 1, 'resolution': 1, 'preserve': 1, 'them,': 2, 'saved': 1, 'nation': 1, 'when': 1, 'on': 3, 'very': 1, 'brink': 1, 'slavery': 1, 'ruin.': 1, 'If': 3, 'these': 2, 'evidence,': 1, 'flatter': 1, 'myself': 2, 'be': 14, 'found': 1, 'there': 4, 'will': 4, 'no': 3, 'miss': 1, 'those': 4, 'lost,': 1, 'my': 8, 'reader': 1, 'may': 2, 'satisfied': 1, 'without': 1, 'them:': 1, 'for': 7, 'imagine,': 1, 'shall': 4, 'neither': 1, 'time,': 1, 'nor': 2, 'inclination': 1, 'repeat': 1, 'pains,': 2, 'fill': 1, 'wanting': 1, 'part': 1, 'answer,': 1, 'tracing': 1, 'Sir': 4, 'Robert': 2, 'again,': 1, 'through': 1, 'windings': 1, 'obscurities,': 1, 'met': 1, 'branches': 1, 'wonderful': 1, 'system.': 1, 'king,': 1, 'body': 2, 'nation,': 1, 'since': 2, 'so': 10, 'thoroughly': 1, 'confuted': 1, 'Hypothesis,': 2, 'suppose': 1, 'hereafter': 1, 'either': 4, 'confidence': 1, 'appear': 2, 'against': 3, 'common': 2, 'safety,': 1, 'again': 1, 'advocate': 1, 'slavery;': 1, 'or': 6, 'weakness': 1, 'deceived': 1, 'contradictions': 1, 'dressed': 1, 'popular': 1, 'stile,': 1, 'well-turned': 1, 'periods:': 1, 'if': 2, 'at': 3, 'himself,': 2, 'parts,': 1, 'untouched,': 1, 'strip': 1, \"Robert's\": 1, 'discourses': 1, 'flourish': 1, 'doubtful': 1, 'expressions,': 1, 'endeavour': 1, 'reduce': 1, 'direct,': 1, 'positive,': 1, 'intelligible': 1, 'propositions,': 1, 'then': 1, 'compare': 1, 'them': 2, 'another,': 1, 'quickly': 1, 'satisfied,': 1, 'never': 1, 'much': 2, 'glib': 1, 'nonsense': 1, 'put': 1, 'together': 1, 'well-sounding': 1, 'English.': 1, 'think': 2, 'examine': 1, 'works': 1, \"thro',\": 1, 'let': 2, 'experiment': 1, 'part,': 1, 'where': 2, 'treats': 1, 'usurpation;': 1, 'try,': 1, 'whether': 1, 'can,': 1, 'skill,': 1, 'intelligible,': 1, 'consistent': 1, 'sense.': 1, 'speak': 1, 'plainly': 1, 'gentleman,': 1, 'long': 1, 'past': 1, 'answering,': 1, 'had': 2, 'pulpit,': 1, 'late': 1, 'years,': 1, 'publicly': 1, 'owned': 1, 'doctrine,': 2, 'made': 1, 'current': 1, 'divinity': 1, 'times.': 1, 'It': 1, 'necessary': 1, 'men,': 1, 'who': 2, 'taking': 1, 'teachers,': 1, 'dangerously': 1, 'misled': 1, 'others,': 1, 'openly': 1, 'shewed': 1, 'authority': 1, 'Patriarch': 1, 'is,': 1, 'whom': 1, 'they': 8, 'blindly': 1, 'followed,': 1, 'retract': 1, 'upon': 2, 'ill': 1, 'grounds': 1, 'vented,': 1, 'cannot': 3, 'maintained;': 1, 'else': 1, 'principles': 1, 'preached': 1, 'gospel;': 1, 'though': 2, 'better': 1, 'author': 1, 'English': 1, 'courtier:': 1, 'writ': 1, 'Robert,': 1, 'taken': 1, 'pains': 1, 'shew': 1, 'mistakes,': 1, 'inconsistencies,': 1, 'want': 1, '(what': 1, 'boasts': 1, 'of,': 1, 'pretends': 1, 'wholly': 1, 'build': 1, 'on)': 1, 'scripture-proofs,': 1, 'men': 1, 'amongst': 1, 'us,': 1, 'who,': 1, 'crying': 1, 'books,': 1, 'espousing': 1, 'save': 1, 'me': 1, 'reproach': 1, 'writing': 1, 'dead': 1, 'adversary.': 1, 'They': 1, 'zealous': 1, 'point,': 1, 'that,': 1, 'done': 3, 'wrong,': 2, 'spare': 1, 'me.': 1, 'wish,': 1, 'truth': 1, 'public': 1, 'would': 1, 'as': 2, 'ready': 1, 'redress': 1, 'it,': 1, 'allow': 1, 'its': 1, 'weight': 1, 'reflection,': 1, 'viz.': 1, 'greater': 1, 'mischief': 1, 'propagating': 1, 'wrong': 1, 'notions': 1, 'might': 1, 'reason': 1, 'complain': 1, 'Drum': 1, 'Ecclesiastic.': 1, 'one,': 2, 'concerned': 1, 'really': 1, 'truth,': 1, 'undertake': 1, 'confutation': 1, 'promise': 1, 'recant': 1, 'mistake,': 1, 'fair': 1, 'conviction;': 1, 'answer': 2, 'difficulties.': 1, 'But': 1, 'must': 1, 'remember': 1, 'two': 1, 'things.': 1, 'First,': 1, 'That': 2, 'cavilling': 1, 'there,': 1, 'some': 1, 'expression,': 1, 'little': 1, 'incident': 1, 'discourse,': 1, 'book.': 1, 'Secondly,': 1, 'take': 1, 'railing': 1, 'arguments,': 1, 'notice,': 1, 'always': 1, 'look': 1, 'bound': 1, 'give': 1, 'satisfaction': 1, 'conscientiously': 1, 'scrupulous': 1}\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    if word in counts:\n",
    "        counts[word] = counts[word] + 1\n",
    "    else:\n",
    "        counts[word] = 1\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[PH]If you don't remember anymore how dictionaries work, go back to the previous chapter and read the part about dictionaries once more.\n",
    "\n",
    "Now that our code is working, we can add it to a function. We define the function `counter` using the `def` keyword. It takes one argument (`list_to_search`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def counter(list_to_search):\n",
    "    counts = {}\n",
    "    for word in list_to_search:\n",
    "        if word in counts:\n",
    "            counts[word] = counts[word] + 1\n",
    "        else:\n",
    "            counts[word] = 1\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[PH]Hopefully we are boring you, but let's go through this function step by step.\n",
    "\n",
    "1. We define a function using `def` and give it the name `counter` (line 1);\n",
    "2. This function takes a single argument `list_to_search` which is the list we want to search through (line 1);\n",
    "3. Next we define a variable `counts` which is an empty dictionary (line 2);\n",
    "4. We loop over all words in `list_to_search` (line 3);\n",
    "5. If the word is already in `counts`, we look up its current value and add 1 to it (line 4-5);\n",
    "6. If the word is not in `counts` (else clause), we add the word to the dictionary and assign it the value 1 (line 6-7);\n",
    "7. Return the result of counts (line 8);\n",
    "\n",
    "Let's try out our new function!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Preprocessing text data\n",
    "\n",
    "[PH]In the previous section we wrote code to compute a frequency distribution of the words in a text stored on our computer. The function `split` is a quick and dirty way of splitting a string into a list of words. However, if we look through the frequency distributions, we notice quite an amount of noice. For instance, the pronoun *her* occurs 4 times, but we also find `her.` occurring 1 time and the capitalized `Her`, also 1 time. Of course we would like te add those counts to that of *her*. As it appears, the tokenization of our text using `split` is fast and simple, but it leaves us with noisy and incorrect frequency distributions. \n",
    "\n",
    "There are essentially two strategies to follow to correct our frequency distributions. The first is to come up with a better procedure of splitting our text into words. The second is to clean-up our text and pass this clean result to the convenient `split` function. For now we will follow the second path.\n",
    "\n",
    "Some words in our text are capitalized. To lowercase these words, Python provides the function `lower`. It operates on strings:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 Converting to lower (or upper) case\n",
    "\n",
    "A standard procedure in text-processing is lowercasing. This converts all capital characters to lowercase, such as in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Donald Duck'.lower())\n",
    "\n",
    "# Or the same\n",
    "\n",
    "name = 'Trevor Noah'\n",
    "print(name.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, why would we do this? The choice for lowercasing is arbitrary, we could as uppercase the whole text. The point here is **uniformisation**, i.e. we want to discard differences between elements that are not relevant to our research question. We, here, make the explicit choice to treat 'Hamburger' and 'hamburger' as the same item. We want to count them as the same word. \n",
    "\n",
    "But equally, if a word starts with a capital because it is located at the beginning, or somewhere else in the sentence, it remains the same word from a semantic point of view (in the majority of the cases)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Don't lowercase this!\".upper())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, this is a choice, and should always be reported."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 Deleting punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "[PH]Lowercasing solves our problem with miscounting capitalized words, leaving us with the problem of punctuation. The function `replace` is just the function we're looking for. It takes two arguments: (1) the string we would like to replace and (2) the string we want to replace the first argument with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please remove all dots from this sentence\n"
     ]
    }
   ],
   "source": [
    "x = 'Please. remove. all. dots. from. this. sentence.'\n",
    "x = x.replace(\".\", \"\")\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[PH]We would like to remove all punctuation from a text, not just dots and commas. We will write a function called `remove_punc` that removes all (simple) punctuation from a text. Again, there are many ways in which we can write this function. We will show you two of them. The first strategy is to repeatedly call `replace` on the same string each time replacing a different punctuation character with an empty string. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "from string import punctuation\n",
    "print(punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commas as it turns out are overestimated Dots however even more so\n"
     ]
    }
   ],
   "source": [
    "def remove_punc(text):\n",
    "    for marker in punctuation:\n",
    "        text = text.replace(marker, \"\")\n",
    "    return text\n",
    "\n",
    "short_text = \"Commas, as it turns out, are overestimated. Dots, however, even more so!\"\n",
    "print(remove_punc(short_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[PH] Now it is time to put everything together. We want to write a function `clean_text` that takes as argument a text represented by string. The function should return this string with all punctuation removed and all characters lowercased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    # insert your code here\n",
    "    return remove_punc(text.lower())\n",
    "    \n",
    "# The following test should print True if your code is correct \n",
    "short_text = \"Commas, as it turns out, are overestimated. Dots, however, even more so!\"\n",
    "print(clean_text(short_text) == \n",
    "      \"commas as it turns out are overestimated dots however even more so\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Counting (the easy way)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'the': 40, 'of': 31, 'to': 30, 'and': 28, 'in': 14, 'be': 14, 'have': 13, 'I': 13, 'his': 12, 'not': 10, 'so': 10, 'is': 8, 'with': 8, 'AND': 8, 'my': 8, 'they': 8, 'which': 7, 'that': 7, 'he': 7, 'for': 7, 'an': 6, 'a': 6, 'all': 6, 'or': 6, 'OF': 5, 'by': 5, 'has': 5, '*': 5, 'THE': 5, 'him': 5, 'should': 5, 'up': 5, 'any': 5, 'The': 4, 'text': 4, '1.': 4, 'this': 4, 'than': 4, 'it': 4, 'are': 4, 'there': 4, 'will': 4, 'those': 4, 'shall': 4, 'Sir': 4, 'either': 4, 'was': 3, 'been': 3, 'from': 3, 'only': 3, 'C.': 3, 'R.': 3, 'were': 3, 'here': 3, 'what': 3, 'worth': 3, 'our': 3, 'make': 3, 'one': 3, 'their': 3, 'on': 3, 'If': 3, 'no': 3, 'against': 3, 'at': 3, 'cannot': 3, 'done': 3, 'GOVERNMENT': 2, 'LOCKE': 2, 'Treatise': 2, 'published': 2, 'several': 2, 'times': 2, 'Locke': 2, 'edition': 2, 'words': 2, '1690': 2, 'TWO': 2, 'TREATISES': 2, 'BY': 2, 'A.': 2, 'B.': 2, 'RIVINGTON,': 2, 'W.': 2, 'S.': 2, 'T.': 2, 'GOVERNMENT.': 2, 'present': 2, 'last': 2, 'concerning': 2, 'government;': 2, 'papers': 2, 'more': 2, 'while': 2, 'hope': 2, 'great': 2, 'people,': 2, 'prince': 2, 'justify': 2, 'just': 2, 'them,': 2, 'these': 2, 'myself': 2, 'may': 2, 'nor': 2, 'pains,': 2, 'Robert': 2, 'body': 2, 'since': 2, 'Hypothesis,': 2, 'appear': 2, 'common': 2, 'if': 2, 'himself,': 2, 'them': 2, 'much': 2, 'think': 2, 'let': 2, 'where': 2, 'had': 2, 'doctrine,': 2, 'who': 2, 'upon': 2, 'though': 2, 'wrong,': 2, 'as': 2, 'one,': 2, 'answer': 2, 'That': 2, 'SECOND': 1, 'TREATISE': 1, 'JOHN': 1, 'Digitized': 1, 'Dave': 1, 'Gowan': 1, '<dgowan@tfn.net>.': 1, 'John': 1, \"Locke's\": 1, '\"Second': 1, 'Government\"': 1, '1690.': 1, 'complete': 1, 'unabridged': 1, 'republished': 1, 'edited': 1, 'commentaries.': 1, 'This': 1, 'recovered': 1, 'entire': 1, 'paperback': 1, 'book,': 1, '\"John': 1, 'Second': 1, 'Government\",': 1, 'Edited,': 1, 'Introduction,': 1, 'By': 1, 'C.B.': 1, 'McPherson,': 1, 'Hackett': 1, 'Publishing': 1, 'Company,': 1, 'Indianapolis': 1, 'Cambridge,': 1, '1980.': 1, 'None': 1, 'McPherson': 1, 'included': 1, 'Etext': 1, 'below;': 1, 'original': 1, 'contained': 1, 'included.': 1, 'free': 1, 'copyright.': 1, 'IOHN': 1, 'SALUS': 1, 'POPULI': 1, 'SUPREMA': 1, 'LEX': 1, 'ESTO': 1, 'LONDON': 1, 'PRINTED': 1, 'MDCLXXXVIII': 1, 'REPRINTED,': 1, 'SIXTH': 1, 'TIME,': 1, 'MILLAR,': 1, 'H.': 1, 'WOODFALL,': 1, 'WHISTON': 1, 'WHITE,': 1, 'L.': 1, 'DAVIS': 1, 'REYMERS,': 1, 'BALDWIN,': 1, 'HAWES': 1, 'CLARKE': 1, 'COLLINS;': 1, 'IOHNSTON,': 1, 'OWEN,': 1, 'RICHARDSON,': 1, 'CROWDER,': 1, 'LONGMAN,': 1, 'LAW,': 1, 'E.': 1, 'DILLY,': 1, 'WITHY,': 1, 'WARE,': 1, 'BAKER,': 1, 'PAYNE,': 1, 'SHUCKBURGH,': 1, 'HINXMAN': 1, 'MDCCLXIII': 1, 'IN': 1, 'FORMER': 1, 'FALSE': 1, 'PRINCIPLES': 1, 'FOUNDATION': 1, 'SIR': 1, 'ROBERT': 1, 'FILMER': 1, 'HIS': 1, 'FOLLOWERS': 1, 'ARE': 1, 'DETECTED': 1, 'OVERTHROWN.': 1, 'LATTER': 1, 'IS': 1, 'AN': 1, 'ESSAY': 1, 'CONCERNING': 1, 'TRUE': 1, 'ORIGINAL': 1, 'EXTENT': 1, 'END': 1, 'CIVIL': 1, '1764': 1, \"EDITOR'S\": 1, 'NOTE': 1, 'Edition': 1, 'Book': 1, 'collated': 1, 'first': 1, 'three': 1, 'Editions,': 1, 'during': 1, \"Author's\": 1, 'Life,': 1, 'but': 1, 'also': 1, 'Advantage': 1, 'Corrections': 1, 'Improvements,': 1, 'Copy': 1, 'delivered': 1, 'Mr.': 1, 'Peter': 1, 'Coste,': 1, 'communicated': 1, 'Editor,': 1, 'now': 1, 'lodged': 1, 'Christ': 1, 'College,': 1, 'Cambridge.': 1, 'PREFACE': 1, 'Reader,': 1, 'thou': 1, 'hast': 1, 'beginning': 1, 'end': 1, 'discourse': 1, 'fate': 1, 'otherwise': 1, 'disposed': 1, 'filled': 1, 'middle,': 1, 'rest,': 1, 'tell': 1, 'thee.': 1, 'These,': 1, 'remain,': 1, 'sufficient': 1, 'establish': 1, 'throne': 1, 'restorer,': 1, 'King': 1, 'William;': 1, 'good': 1, 'title,': 1, 'consent': 1, 'being': 1, 'lawful': 1, 'governments,': 1, 'fully': 1, 'clearly,': 1, 'Christendom;': 1, 'world': 1, 'people': 1, 'England,': 1, 'whose': 1, 'love': 1, 'natural': 1, 'rights,': 1, 'resolution': 1, 'preserve': 1, 'saved': 1, 'nation': 1, 'when': 1, 'very': 1, 'brink': 1, 'slavery': 1, 'ruin.': 1, 'evidence,': 1, 'flatter': 1, 'found': 1, 'miss': 1, 'lost,': 1, 'reader': 1, 'satisfied': 1, 'without': 1, 'them:': 1, 'imagine,': 1, 'neither': 1, 'time,': 1, 'inclination': 1, 'repeat': 1, 'fill': 1, 'wanting': 1, 'part': 1, 'answer,': 1, 'tracing': 1, 'again,': 1, 'through': 1, 'windings': 1, 'obscurities,': 1, 'met': 1, 'branches': 1, 'wonderful': 1, 'system.': 1, 'king,': 1, 'nation,': 1, 'thoroughly': 1, 'confuted': 1, 'suppose': 1, 'hereafter': 1, 'confidence': 1, 'safety,': 1, 'again': 1, 'advocate': 1, 'slavery;': 1, 'weakness': 1, 'deceived': 1, 'contradictions': 1, 'dressed': 1, 'popular': 1, 'stile,': 1, 'well-turned': 1, 'periods:': 1, 'parts,': 1, 'untouched,': 1, 'strip': 1, \"Robert's\": 1, 'discourses': 1, 'flourish': 1, 'doubtful': 1, 'expressions,': 1, 'endeavour': 1, 'reduce': 1, 'direct,': 1, 'positive,': 1, 'intelligible': 1, 'propositions,': 1, 'then': 1, 'compare': 1, 'another,': 1, 'quickly': 1, 'satisfied,': 1, 'never': 1, 'glib': 1, 'nonsense': 1, 'put': 1, 'together': 1, 'well-sounding': 1, 'English.': 1, 'examine': 1, 'works': 1, \"thro',\": 1, 'experiment': 1, 'part,': 1, 'treats': 1, 'usurpation;': 1, 'try,': 1, 'whether': 1, 'can,': 1, 'skill,': 1, 'intelligible,': 1, 'consistent': 1, 'sense.': 1, 'speak': 1, 'plainly': 1, 'gentleman,': 1, 'long': 1, 'past': 1, 'answering,': 1, 'pulpit,': 1, 'late': 1, 'years,': 1, 'publicly': 1, 'owned': 1, 'made': 1, 'current': 1, 'divinity': 1, 'times.': 1, 'It': 1, 'necessary': 1, 'men,': 1, 'taking': 1, 'teachers,': 1, 'dangerously': 1, 'misled': 1, 'others,': 1, 'openly': 1, 'shewed': 1, 'authority': 1, 'Patriarch': 1, 'is,': 1, 'whom': 1, 'blindly': 1, 'followed,': 1, 'retract': 1, 'ill': 1, 'grounds': 1, 'vented,': 1, 'maintained;': 1, 'else': 1, 'principles': 1, 'preached': 1, 'gospel;': 1, 'better': 1, 'author': 1, 'English': 1, 'courtier:': 1, 'writ': 1, 'Robert,': 1, 'taken': 1, 'pains': 1, 'shew': 1, 'mistakes,': 1, 'inconsistencies,': 1, 'want': 1, '(what': 1, 'boasts': 1, 'of,': 1, 'pretends': 1, 'wholly': 1, 'build': 1, 'on)': 1, 'scripture-proofs,': 1, 'men': 1, 'amongst': 1, 'us,': 1, 'who,': 1, 'crying': 1, 'books,': 1, 'espousing': 1, 'save': 1, 'me': 1, 'reproach': 1, 'writing': 1, 'dead': 1, 'adversary.': 1, 'They': 1, 'zealous': 1, 'point,': 1, 'that,': 1, 'spare': 1, 'me.': 1, 'wish,': 1, 'truth': 1, 'public': 1, 'would': 1, 'ready': 1, 'redress': 1, 'it,': 1, 'allow': 1, 'its': 1, 'weight': 1, 'reflection,': 1, 'viz.': 1, 'greater': 1, 'mischief': 1, 'propagating': 1, 'wrong': 1, 'notions': 1, 'might': 1, 'reason': 1, 'complain': 1, 'Drum': 1, 'Ecclesiastic.': 1, 'concerned': 1, 'really': 1, 'truth,': 1, 'undertake': 1, 'confutation': 1, 'promise': 1, 'recant': 1, 'mistake,': 1, 'fair': 1, 'conviction;': 1, 'difficulties.': 1, 'But': 1, 'must': 1, 'remember': 1, 'two': 1, 'things.': 1, 'First,': 1, 'cavilling': 1, 'there,': 1, 'some': 1, 'expression,': 1, 'little': 1, 'incident': 1, 'discourse,': 1, 'book.': 1, 'Secondly,': 1, 'take': 1, 'railing': 1, 'arguments,': 1, 'notice,': 1, 'always': 1, 'look': 1, 'bound': 1, 'give': 1, 'satisfaction': 1, 'conscientiously': 1, 'scrupulous': 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "counter = Counter(words)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 40),\n",
       " ('of', 31),\n",
       " ('to', 30),\n",
       " ('and', 28),\n",
       " ('in', 14),\n",
       " ('be', 14),\n",
       " ('have', 13),\n",
       " ('I', 13),\n",
       " ('his', 12),\n",
       " ('not', 10)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What a disappointment, you might think at this point. All this work, just to obtain a list of these 'boring' words? The most frequents words are mostly not very informative, at least not if you want to pin down the topic of a text. These most frequent words are often called stopwords. \n",
    "\n",
    "On a side note: words have a rather persistent distribution, as small set of words is very frequent. For example the 10 most frequent words take around 26% of the total, put differently 0.1% of the total vocabulary (the ten most frequent) alone are enough to compose 26% of the text. For n=100: 60% of the text is composed from solely 1.4 percent of the vocabulary. If you want to compress your text, just throw away the 10 most frequent words!\n",
    "\n",
    "The code below allows you to verify this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.587360594795538\n",
      "53.300000000000004\n"
     ]
    }
   ],
   "source": [
    "topn = 100\n",
    "total_words = len(words)\n",
    "total_topn = sum([v for w,v in counter.most_common(topn)])\n",
    "print(topn/len(set(words))*100)\n",
    "print(total_topn/total_words*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopw = stopwords.words('english')\n",
    "print(stopw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wf_filtered = Counter(w for w in words if w not in stopw)\n",
    "wf_filtered.most_common(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5. Storing Output\n",
    "### CSV Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The previous steps reduced a book to table of word frequencies. For sure, you do not want to repeat this procedure every time but save it as an intermediate result. The optimal format is a CSV file, with CSV abbreviation Comma Separated Value. The comma in this case is called the **delimiter** the value that separates the items on each row. The end of the row is usually by a hard return.\n",
    "\n",
    "The content of an example CSV \n",
    "\n",
    "``\n",
    "'ideas', 1398\n",
    "'one', 911\n",
    "'idea', 886\n",
    "``\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "content = ''\n",
    "for key,value in wf_filtered.items():\n",
    "    line = key+','+str(value)+'\\n'\n",
    "    content+=line\n",
    "    \n",
    "# or more concise\n",
    "#content = '\\n'.join([\"{},{}\".format(k,v) for k,v in wf.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = \"data/wf.csv\"\n",
    "with open(filename, \"w\") as outfile:\n",
    "    outfile.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!ls data\n",
    "!head data/wf.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  Go to Project Gutenberg (http://www.gutenberg.org) and download your favorite out- of-copyright book in plain text format. Make a frequency dictionary of the words in the novel. Sort the words in the dictionary by frequency and write it to a text file called `frequencies.txt`. Make sure your program ignores capitalization as well as punctuation (hint: check out `string.punctuation` online!). Search the web in order to find out how you can sort a dictionary -- this is not easy, because you might have to import another module."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
