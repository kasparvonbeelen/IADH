{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Code for Loading and Manipulating Data\n",
    "- Loading multiple files (Movie Reviews)\n",
    "- Netvizz\n",
    "- Political Mashup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for more detail have a look at Notebook 5.2 Reading and Writing Files\n",
    "import os # import the operating system library\n",
    "import codecs\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading a collection of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to use this example download this file and unzip it: http://www.cs.cornell.edu/people/pabo/movie-review-data/review_polarity.tar.gz\n",
    "path_to_neg_reviews = 'review_polarity/txt_sentoken/neg/' # assuming this folder is in same directory as the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = os.listdir(path_to_neg_reviews) # list all the files in the folder \n",
    "print(reviews[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import regexp_tokenize\n",
    "\n",
    "neg_reviews_tokens_all = [] # here we will store all the tokens\n",
    "for review in reviews:\n",
    "    review_text = open(os.path.join(path_to_neg_reviews,review),'r').read() # open and read the file\n",
    "    # if this fails try codecs.open(os.path.join(path_to_neg_reviews,review),'r',encoding='utf-8').read()\n",
    "    tokens = regexp_tokenize(review_text,pattern='\\w+') # tokenize the text\n",
    "    neg_reviews_tokens_all.extend(tokens) # add tokens to the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_reviews_nlkt_text = nltk.text.Text(neg_reviews_tokens_all) # convert list of tokens to an NLTK Text object\n",
    "neg_reviews_nlkt_text.concordance('awful') # use the NLTK Text methods, see Notebook 4.2 for more examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data from Netvizz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_to_netvizz_files = 'page_15704546335_2018_01_24_10_02_35/' # set the path to your files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netvizz_files = os.listdir(path_to_netvizz_files) # list all the files in this directory\n",
    "print(netvizz_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topcomments_path = os.path.join(path_to_netvizz_files,'page_15704546335_2018_01_24_10_02_35_topcomments.tab')\n",
    "print(topcomments_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topcomments = open(topcomments_path,'r').read().strip() # open the files, delete trailing whitespaces with the .strip() method\n",
    "print(topcomments[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = topcomments.split('\\n')\n",
    "print(len(rows))\n",
    "print(rows[0]) # the first row is the header\n",
    "print(rows[1]) # the second row a top comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for row in rows[1:]: # ignore the first row which is the header\n",
    "    cells = row.split('\\t') # cells are tab separated, a tab in python is \"\\t\"\n",
    "    data.append(cells) # add the cells to the data list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taco_bell = []\n",
    "# collect all posts mentioning Taco Bell\n",
    "for row in data:\n",
    "    if 'taco bell' in row[1].lower(): # text is saved as the second item (location index 1) in each row, we also lowercase the text\n",
    "        taco_bell.append(row) # append the row to the taco bell list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(taco_bell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opening and loading data from Political Mashup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv # we need another module here because the separator (',') also appears in the text\n",
    "text = open('hits.csv','r').read()\n",
    "data = [row for row in csv.reader(text.split('\\n'), quotechar='\"', delimiter=',')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[0])\n",
    "print(data[1])\n",
    "print(data[1][-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
